{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5539feb-e99e-4649-bd80-c9a982680f8c",
   "metadata": {},
   "source": [
    "# OCR Processing Script for Swedish RSA PDFs - Improved Version\n",
    "\n",
    "## Overview\n",
    "\n",
    "This improved OCR script processes Swedish municipal RSA (Risk and Vulnerability Analysis) PDF documents that failed standard text extraction. It uses Tesseract OCR with Swedish language support and outputs data in a format directly compatible with the readtext R package.\n",
    "\n",
    "\n",
    "**Class and Method Documentation:**\n",
    "```python\n",
    "@dataclass\n",
    "class DocumentMetadata:\n",
    "    \"\"\"Metadata extracted from RSA document filename.\n",
    "\n",
    "    Attributes:\n",
    "        filename: Original PDF filename\n",
    "        municipality: Swedish municipality name\n",
    "        year: Publication year (4-digit string or 'unknown')\n",
    "        is_masked: Whether document is marked as 'Maskad' (redacted)\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_filename(cls, filename: str) -> DocumentMetadata:\n",
    "        \"\"\"Parse metadata from RSA document filename.\n",
    "\n",
    "        Expected format: RSA [municipality] [year] [Maskad].pdf\n",
    "\n",
    "        Args:\n",
    "            filename: PDF filename to parse\n",
    "\n",
    "        Returns:\n",
    "            DocumentMetadata instance with extracted fields\n",
    "\n",
    "        Examples:\n",
    "            >>> DocumentMetadata.from_filename(\"RSA Ale 2015 Maskad.pdf\")\n",
    "            DocumentMetadata(filename='RSA Ale 2015 Maskad.pdf',\n",
    "                           municipality='Ale', year='2015', is_masked=True)\n",
    "        \"\"\"\n",
    "```\n",
    "\n",
    "## Installation\n",
    "\n",
    "### System Dependencies\n",
    "\n",
    "**Ubuntu/Debian:**\n",
    "```bash\n",
    "sudo apt-get update\n",
    "sudo apt-get install tesseract-ocr tesseract-ocr-swe poppler-utils\n",
    "```\n",
    "\n",
    "**macOS:**\n",
    "```bash\n",
    "brew install tesseract tesseract-lang poppler\n",
    "```\n",
    "\n",
    "### Python Dependencies\n",
    "\n",
    "```bash\n",
    "pip install pytesseract pdf2image pillow pandas tqdm pyarrow\n",
    "```\n",
    "\n",
    "**Note:** Swedish language support (`tesseract-ocr-swe`) is **required**. The script will fail if it's not installed.\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Command Line\n",
    "\n",
    "```bash\n",
    "# Process all PDFs\n",
    "python ocr_swedish_pdfs_improved.py -i ./pdfs -o ./output\n",
    "\n",
    "# Process specific files\n",
    "python ocr_swedish_pdfs_improved.py -i ./pdfs -o ./output -f failed_files.txt\n",
    "\n",
    "# Check installation\n",
    "python ocr_swedish_pdfs_improved.py --check-only\n",
    "\n",
    "# Higher DPI for better quality (slower)\n",
    "python ocr_swedish_pdfs_improved.py -i ./pdfs -o ./output --dpi 400\n",
    "```\n",
    "\n",
    "### Jupyter Lab Usage (Recommended)\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "from ocr_swedish_pdfs_improved import run_pipeline, ProcessingConfig\n",
    "\n",
    "# Configure processing\n",
    "config = ProcessingConfig(\n",
    "    language=\"swe+eng\",  # Swedish + English for mixed content\n",
    "    dpi=300,\n",
    "    min_text_length=500,\n",
    "    workers=1,  # Use 1 for Jupyter (multiprocessing can cause issues)\n",
    ")\n",
    "\n",
    "# Run the pipeline\n",
    "results, summary = run_pipeline(\n",
    "    input_dir=Path(\"/path/to/pdfs\"),\n",
    "    output_dir=Path(\"./ocr_output\"),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# Check results\n",
    "print(f\"Processed: {summary.total_files}\")\n",
    "print(f\"Successful: {summary.successful}\")\n",
    "print(f\"Failed: {summary.failed_short + summary.failed_other}\")\n",
    "\n",
    "# Access individual results\n",
    "for result in results:\n",
    "    if result.status.is_success():\n",
    "        print(f\"{result.file}: {result.word_count} words\")\n",
    "```\n",
    "\n",
    "### Process Specific Files from List\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "from ocr_swedish_pdfs_improved import run_pipeline, ProcessingConfig\n",
    "\n",
    "results, summary = run_pipeline(\n",
    "    input_dir=Path(\"/path/to/pdfs\"),\n",
    "    output_dir=Path(\"./ocr_output\"),\n",
    "    file_list=Path(\"failed_files.txt\"),  # One filename per line\n",
    "    config=ProcessingConfig(workers=1),\n",
    ")\n",
    "```\n",
    "\n",
    "## Output Files\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `ocr_readtext_format.parquet` | **Primary output** - matches readtext format (file, text columns) |\n",
    "| `ocr_full_results.parquet` | All metadata and processing details |\n",
    "| `ocr_results_summary.csv` | Summary without text content |\n",
    "| `still_failed_files.txt` | Files that failed OCR |\n",
    "| `*.txt` | Individual text files (optional) |\n",
    "\n",
    "## Integration with Stanza Pipeline\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load readtext success (convert from RDS if needed, or use parquet)\n",
    "# If you have readtext_success.rds, convert it first:\n",
    "# import pyreadr\n",
    "# readtext_df = pyreadr.read_r('readtext_success.rds')[None]\n",
    "# readtext_df.to_parquet('readtext_success.parquet')\n",
    "\n",
    "readtext_df = pd.read_parquet('readtext_success.parquet')\n",
    "ocr_df = pd.read_parquet('ocr_output/ocr_readtext_format.parquet')\n",
    "\n",
    "# Combine\n",
    "combined_df = pd.concat([readtext_df, ocr_df], ignore_index=True)\n",
    "\n",
    "print(f\"Total documents: {len(combined_df)}\")\n",
    "\n",
    "# Continue with existing Stanza pipeline...\n",
    "```\n",
    "\n",
    "## Architecture Diagram\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                        CLI / API                            │\n",
    "│  main() ←→ run_pipeline() ←→ create_argument_parser()       │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    Configuration Layer                       │\n",
    "│  ProcessingConfig │ Constants │ DependencyChecker           │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    Discovery Layer                           │\n",
    "│  discover_pdf_files() │ DocumentMetadata.from_filename()    │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    Processing Layer                          │\n",
    "│  BatchProcessor │ process_single_document │ OCREngine       │\n",
    "│  ImagePreprocessor (Strategy Pattern)                       │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                      Output Layer                            │\n",
    "│  OutputWriter │ ProcessingSummary │ OCRResult               │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## Performance Considerations\n",
    "\n",
    "- **Parallel Processing**: Use `--workers N` for multi-core systems\n",
    "- **DPI Trade-off**: Higher DPI = better quality but slower processing\n",
    "- **Memory**: Each worker loads entire PDFs into memory; adjust workers accordingly\n",
    "- **Disk I/O**: Parquet output is faster than CSV for large datasets\n",
    "\n",
    "## Extending the Script\n",
    "\n",
    "### Custom Preprocessing\n",
    "\n",
    "```python\n",
    "class ContrastEnhancer(ImagePreprocessor):\n",
    "    def __init__(self, factor: float = 1.5):\n",
    "        from PIL import ImageEnhance\n",
    "        self.factor = factor\n",
    "    \n",
    "    def process(self, image):\n",
    "        from PIL import ImageEnhance\n",
    "        enhancer = ImageEnhance.Contrast(image)\n",
    "        return enhancer.enhance(self.factor)\n",
    "\n",
    "# Use custom preprocessor\n",
    "preprocessor = CompositePreprocessor([\n",
    "    GrayscalePreprocessor(),\n",
    "    ContrastEnhancer(factor=2.0),\n",
    "    ThresholdPreprocessor(threshold=140),\n",
    "])\n",
    "engine = OCREngine(config, preprocessor=preprocessor)\n",
    "```\n",
    "\n",
    "### Custom Output Format\n",
    "\n",
    "```python\n",
    "class CustomOutputWriter(OutputWriter):\n",
    "    def write_all(self, results):\n",
    "        paths = super().write_all(results)\n",
    "        # Add custom format\n",
    "        paths['custom'] = self._write_custom_format(results)\n",
    "        return paths\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
